{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from dataset import VoxDataset, ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VoxDataset(transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8  # 80% for training, 20% for testing\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "# Use random_split to create training and testing datasets\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5718, grad_fn=<UnbindBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(dataloader)\n",
    "# emb, mesh = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(384, 192),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # nn.Linear(192, 384),\n",
    "            # nn.Tanh(),\n",
    "            nn.Linear(384, 500),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(500, 768),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(768, 1000),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1000, 1536),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1536, 2000),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(2000, 3072),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(3072, 5000),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(5000, 6144),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(6144, 8000),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(8000, 10000),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(10000, 12288),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12288, 15069),\n",
    "            nn.Tanh()\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #encoded = self.encoder(x)\n",
    "        encoded = x\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "model = AutoEncoder().to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5, \n",
    "weight_decay=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_checkpoint(x):\n",
    "    return checkpoint(model, x, use_reentrant=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1346/1346 [19:24<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Loss:0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1346/1346 [21:44<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2, Loss:0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1346/1346 [18:53<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3, Loss:0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1346/1346 [21:40<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4, Loss:0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1346/1346 [22:25<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5, Loss:0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 51/1346 [00:42<18:28,  1.17it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "outputs = []\n",
    "train_loss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for emb, mesh in tqdm(train_dataloader):\n",
    "        emb = emb.to(device)\n",
    "        mesh = mesh.to(device)\n",
    "        recon = model_checkpoint(emb)\n",
    "        loss = criterion(recon, mesh)\n",
    "\n",
    "        emb = emb.detach()\n",
    "        mesh = mesh.detach()\n",
    "        recon = recon.detach()\n",
    "\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch:{epoch+1}, Loss:{loss.item():.4f}\")\n",
    "    outputs.append((epoch,emb,recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03406316414475441\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Loss: {sum(train_loss)/len(train_loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 59.40it/s]\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "test_loss = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, outputs in tqdm(test_dataloader):\n",
    "        # Forward pass through the encoder\n",
    "        # encoded_representation = autoencoder.encoder(inputs)\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = outputs.to(device)\n",
    "        # Forward pass through the decoder\n",
    "        reconstructed_output = model.decoder(inputs)\n",
    "\n",
    "        # Reconstruction loss (optional, depending on your use case)\n",
    "        reconstruction_loss = criterion(reconstructed_output, outputs)\n",
    "\n",
    "        # Print or use the reconstructed output as needed\n",
    "        decoded.append(VoxDataset.to_mesh_points(reconstructed_output))\n",
    "\n",
    "        test_loss.append(reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.01122639887034893\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Loss: {sum(test_loss)/len(test_loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "for index, i in enumerate(decoded):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(i)\n",
    "    # o3d.visualization.draw_geometries([pcd])\n",
    "    o3d.io.write_point_cloud(f\"./Test/data{index}.ply\", pcd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Loss: 1486.4837646484375"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
