{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from dataset_tf import VoxDataset, DataGenerator\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "# from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VoxDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107640\n"
     ]
    }
   ],
   "source": [
    "ids = dataset.get_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.6 * DATASET_SIZE)\n",
    "val_size = int(0.2 * DATASET_SIZE)\n",
    "test_size = DATASET_SIZE - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3229\n",
      "1077\n",
      "1076\n"
     ]
    }
   ],
   "source": [
    "print(train_size)\n",
    "print(test_size)\n",
    "print(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(ids)\n",
    "\n",
    "# Split the indices into training, validation, and test sets\n",
    "train_indices = ids[:train_size]\n",
    "val_indices = ids[train_size:train_size + val_size]\n",
    "test_indices = ids[train_size + val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3229"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = VoxDataset(ids=train_indices)\n",
    "test = VoxDataset(ids=test_indices)\n",
    "val = VoxDataset(ids=val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64580\n",
      "21540\n",
      "21520\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataGenerator(train, batch_size=32)\n",
    "test = DataGenerator(test, batch_size=1)\n",
    "val = DataGenerator(val, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 23:23:49.885054: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-03-16 23:23:49.885074: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-03-16 23:23:49.885080: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-03-16 23:23:49.885108: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-16 23:23:49.885123: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([384])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([15069])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def AutoEncoder():\n",
    "    # Define input layer\n",
    "    input_layer = tf.keras.layers.Input(shape=(384,))\n",
    "    \n",
    "    # Encoder layers\n",
    "    # encoder = tf.keras.layers.Dense(192, activation='ReLU')(input_layer)\n",
    "    \n",
    "    # Decoder layers\n",
    "    decoder = tf.keras.layers.Dense(500, activation='ReLU')(input_layer)\n",
    "    decoder = tf.keras.layers.Dense(768, activation='ReLU')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(1000, activation='ReLU')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(1536, activation='ReLU')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(2000, activation='ReLU')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(3072, activation='ReLU')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(5000, activation='ReLU')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(6144, activation='ReLU')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(8000, activation='ReLU')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(10000, activation='ReLU')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(12288, activation='ReLU')(decoder)\n",
    "    decoder_output = tf.keras.layers.Dense(15069, activation='ReLU')(decoder)\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.models.Model(inputs=input_layer, outputs=decoder_output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 23:23:50.999117: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   9/2019 [..............................] - ETA: 9:04 - loss: 87958.7109 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.00001)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 100\n",
    "batch_size = 8\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "# Train the model using model.fit\n",
    "model.fit(train, epochs=num_epochs, batch_size=batch_size, validation_data=val, \n",
    "          callbacks=[early_stopping]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 384)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               192500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 768)               384768    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1000)              769000    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1536)              1537536   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2000)              3074000   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3072)              6147072   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 5000)              15365000  \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6144)              30726144  \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8000)              49160000  \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10000)             80010000  \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 12288)             122892288 \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 15069)             185182941 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 495441249 (1.85 GB)\n",
      "Trainable params: 495441249 (1.85 GB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21540/21540 [==============================] - 397s 18ms/step - loss: 33909.8945 - accuracy: 0.0355\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 3.5515%\n",
      "Loss: 33909.8945\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {acc*100:.4f}%\\nLoss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naweenk/miniforge3/envs/tf/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('./model.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21540/21540 [15:05<00:00, 23.79it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(test):\n",
    "    pred = model.predict(i[0], verbose=0)*279.79984\n",
    "    y_pred.append(VoxDataset.to_mesh_points(pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "for index, i in enumerate(y_pred):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(i)\n",
    "    # o3d.visualization.draw_geometries([pcd])\n",
    "    o3d.io.write_point_cloud(f\"./Test/data{index}.ply\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([205.21123 , 129.36862 ,  88.51011 , ..., 106.495544, 161.81659 ,\n",
       "       149.57361 ], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  64.67786 , -139.8999  ,  -54.854828], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy.spatial import Delaunay\n",
    "# import trimesh\n",
    "\n",
    "# points = y_pred[0]\n",
    "\n",
    "# pcd = o3d.geometry.PointCloud()\n",
    "# pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "# # Estimate normals for the point cloud\n",
    "# pcd.estimate_normals()\n",
    "\n",
    "# # Create a surface mesh from the point cloud using Poisson reconstruction\n",
    "# mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=9)\n",
    "\n",
    "# # Visualize the mesh (optional)\n",
    "# o3d.visualization.draw_geometries([mesh])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "head",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
